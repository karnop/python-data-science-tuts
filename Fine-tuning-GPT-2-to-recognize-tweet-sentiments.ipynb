{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30805,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/manavmaheshsanger/fine-tuning-gpt-2-to-recognize-tweet-sentiments?scriptVersionId=211387907\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"!pip install datasets pandas transformers evaluate numpy torch","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-12-05T13:28:28.834268Z","iopub.execute_input":"2024-12-05T13:28:28.834557Z","iopub.status.idle":"2024-12-05T13:28:38.674431Z","shell.execute_reply.started":"2024-12-05T13:28:28.834523Z","shell.execute_reply":"2024-12-05T13:28:38.673599Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (3.1.0)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (2.2.3)\nRequirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.46.3)\nCollecting evaluate\n  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (1.26.4)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (2.4.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from datasets) (3.15.1)\nRequirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (17.0.0)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.8)\nRequirement already satisfied: requests>=2.32.2 in /opt/conda/lib/python3.10/site-packages (from datasets) (2.32.3)\nRequirement already satisfied: tqdm>=4.66.3 in /opt/conda/lib/python3.10/site-packages (from datasets) (4.66.4)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.4.1)\nRequirement already satisfied: multiprocess<0.70.17 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.16)\nRequirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.6.0)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.9.5)\nRequirement already satisfied: huggingface-hub>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.26.2)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from datasets) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets) (6.0.2)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas) (2024.1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas) (2024.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2024.5.15)\nRequirement already satisfied: tokenizers<0.21,>=0.20 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.20.3)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.5)\nRequirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch) (4.12.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch) (1.13.3)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch) (3.1.4)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.2.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.5)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->datasets) (3.1.2)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (2024.6.2)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch) (2.1.5)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\nDownloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: evaluate\nSuccessfully installed evaluate-0.4.3\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# Loading and analyzing dataset\nfrom datasets import load_dataset\ndataset = load_dataset(\"mteb/tweet_sentiment_extraction\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-05T13:28:38.676749Z","iopub.execute_input":"2024-12-05T13:28:38.677141Z","iopub.status.idle":"2024-12-05T13:28:41.346653Z","shell.execute_reply.started":"2024-12-05T13:28:38.6771Z","shell.execute_reply":"2024-12-05T13:28:41.345806Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/22.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"27a37829f2c2475ca6891e3b3b17ebcc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train.jsonl:   0%|          | 0.00/3.63M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"898e24e626a9443fbf7dd9a607836744"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"test.jsonl:   0%|          | 0.00/465k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"db8935eede8049c8a93285ea89fe3b4f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/27481 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"45e28fa788274a44ba5587782bd04b44"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/3534 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fb0c5e8936774b70afc1e18090447f83"}},"metadata":{}}],"execution_count":2},{"cell_type":"code","source":"dataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-05T13:28:41.347754Z","iopub.execute_input":"2024-12-05T13:28:41.348585Z","iopub.status.idle":"2024-12-05T13:28:41.354205Z","shell.execute_reply.started":"2024-12-05T13:28:41.348543Z","shell.execute_reply":"2024-12-05T13:28:41.353233Z"}},"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['id', 'text', 'label', 'label_text'],\n        num_rows: 27481\n    })\n    test: Dataset({\n        features: ['id', 'text', 'label', 'label_text'],\n        num_rows: 3534\n    })\n})"},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"dataset[\"train\"]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-05T13:28:41.355948Z","iopub.execute_input":"2024-12-05T13:28:41.356185Z","iopub.status.idle":"2024-12-05T13:28:41.364076Z","shell.execute_reply.started":"2024-12-05T13:28:41.356147Z","shell.execute_reply":"2024-12-05T13:28:41.363362Z"}},"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['id', 'text', 'label', 'label_text'],\n    num_rows: 27481\n})"},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"import pandas as pd\ndf = pd.DataFrame(dataset[\"train\"])\ndf.sample(10)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-05T13:28:41.364824Z","iopub.execute_input":"2024-12-05T13:28:41.365036Z","iopub.status.idle":"2024-12-05T13:28:42.390269Z","shell.execute_reply.started":"2024-12-05T13:28:41.365014Z","shell.execute_reply":"2024-12-05T13:28:42.389347Z"}},"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"               id                                               text  label  \\\n6652   bee1bbb3b9  _EN  we`re waiting you here in Belgrade!! Can`...      1   \n21043  6ae26d3934  Urgh.... feeling like **** today. Bad headache...      0   \n25098  4c5caae011  Watched Adaptation, Interiors, and The Women (...      2   \n20245  645849b925  Just sittin here waitin for my coffee to be fu...      1   \n14180  a146ea7fda  i cant believe this woman talked me into getti...      1   \n21664  851583e0de  http://twitpic.com/4w8l1 - Haaha, my bangs are...      1   \n5892   0736535e65                                 for me they`re not      1   \n4407   3fb8232118    Yeah the spammers are discriminating: none o...      0   \n13134  ba29930e58                       playing machines in actinggg      1   \n3134   57f97a9ac7   dont worry, i will. i HATE it when nobody com...      0   \n\n      label_text  \n6652     neutral  \n21043   negative  \n25098   positive  \n20245    neutral  \n14180    neutral  \n21664    neutral  \n5892     neutral  \n4407    negative  \n13134    neutral  \n3134    negative  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>text</th>\n      <th>label</th>\n      <th>label_text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>6652</th>\n      <td>bee1bbb3b9</td>\n      <td>_EN  we`re waiting you here in Belgrade!! Can`...</td>\n      <td>1</td>\n      <td>neutral</td>\n    </tr>\n    <tr>\n      <th>21043</th>\n      <td>6ae26d3934</td>\n      <td>Urgh.... feeling like **** today. Bad headache...</td>\n      <td>0</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>25098</th>\n      <td>4c5caae011</td>\n      <td>Watched Adaptation, Interiors, and The Women (...</td>\n      <td>2</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>20245</th>\n      <td>645849b925</td>\n      <td>Just sittin here waitin for my coffee to be fu...</td>\n      <td>1</td>\n      <td>neutral</td>\n    </tr>\n    <tr>\n      <th>14180</th>\n      <td>a146ea7fda</td>\n      <td>i cant believe this woman talked me into getti...</td>\n      <td>1</td>\n      <td>neutral</td>\n    </tr>\n    <tr>\n      <th>21664</th>\n      <td>851583e0de</td>\n      <td>http://twitpic.com/4w8l1 - Haaha, my bangs are...</td>\n      <td>1</td>\n      <td>neutral</td>\n    </tr>\n    <tr>\n      <th>5892</th>\n      <td>0736535e65</td>\n      <td>for me they`re not</td>\n      <td>1</td>\n      <td>neutral</td>\n    </tr>\n    <tr>\n      <th>4407</th>\n      <td>3fb8232118</td>\n      <td>Yeah the spammers are discriminating: none o...</td>\n      <td>0</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>13134</th>\n      <td>ba29930e58</td>\n      <td>playing machines in actinggg</td>\n      <td>1</td>\n      <td>neutral</td>\n    </tr>\n    <tr>\n      <th>3134</th>\n      <td>57f97a9ac7</td>\n      <td>dont worry, i will. i HATE it when nobody com...</td>\n      <td>0</td>\n      <td>negative</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"df.columns","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-05T13:28:42.391429Z","iopub.execute_input":"2024-12-05T13:28:42.39172Z","iopub.status.idle":"2024-12-05T13:28:42.398349Z","shell.execute_reply.started":"2024-12-05T13:28:42.391693Z","shell.execute_reply":"2024-12-05T13:28:42.397155Z"}},"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"Index(['id', 'text', 'label', 'label_text'], dtype='object')"},"metadata":{}}],"execution_count":6},{"cell_type":"markdown","source":"## Tokenization","metadata":{}},{"cell_type":"code","source":"from transformers import GPT2Tokenizer","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-05T13:28:42.399542Z","iopub.execute_input":"2024-12-05T13:28:42.399878Z","iopub.status.idle":"2024-12-05T13:28:45.828129Z","shell.execute_reply.started":"2024-12-05T13:28:42.399841Z","shell.execute_reply":"2024-12-05T13:28:45.827188Z"}},"outputs":[{"name":"stderr","text":"The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2fac160372054119960f63eea85efd9c"}},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"# Initializing the gpt-2 tokenizer\ntokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\ntokenizer.pad_token = tokenizer.eos_token\ntokenizer.eos_token","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-05T13:28:45.829207Z","iopub.execute_input":"2024-12-05T13:28:45.829618Z","iopub.status.idle":"2024-12-05T13:28:47.331057Z","shell.execute_reply.started":"2024-12-05T13:28:45.82959Z","shell.execute_reply":"2024-12-05T13:28:47.330134Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"409098422f1040098007ff1e46bffc0c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8b20cd34fcc249848be52cd07f438ec0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6672744645424214b6fbebe9b7789de1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8eac7a9192214e30aeeef305988c77b3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d4578c98415e42fbaa3ae5c0669d51b4"}},"metadata":{}},{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"'<|endoftext|>'"},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"def tokenize(element):\n    return tokenizer(element[\"text\"], padding=\"max_length\", truncation=True)\n\n\ntokenized_data = dataset.map(tokenize, batched=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-05T13:28:47.332216Z","iopub.execute_input":"2024-12-05T13:28:47.33271Z","iopub.status.idle":"2024-12-05T13:29:01.685036Z","shell.execute_reply.started":"2024-12-05T13:28:47.332682Z","shell.execute_reply":"2024-12-05T13:29:01.684306Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/27481 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d797e3b943724eca98467a9e110ac46a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/3534 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"25f7531f53a74b1ebc3dc0c263e6a4b6"}},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"tokenized_data","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-05T13:29:01.687494Z","iopub.execute_input":"2024-12-05T13:29:01.687783Z","iopub.status.idle":"2024-12-05T13:29:01.693833Z","shell.execute_reply.started":"2024-12-05T13:29:01.687755Z","shell.execute_reply":"2024-12-05T13:29:01.69285Z"}},"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['id', 'text', 'label', 'label_text', 'input_ids', 'attention_mask'],\n        num_rows: 27481\n    })\n    test: Dataset({\n        features: ['id', 'text', 'label', 'label_text', 'input_ids', 'attention_mask'],\n        num_rows: 3534\n    })\n})"},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"tokenized_data[\"train\"][\"input_ids\"][0][:5]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-05T13:29:01.694896Z","iopub.execute_input":"2024-12-05T13:29:01.695192Z","iopub.status.idle":"2024-12-05T13:29:13.028277Z","shell.execute_reply.started":"2024-12-05T13:29:01.695166Z","shell.execute_reply":"2024-12-05T13:29:13.027367Z"}},"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"[314, 63, 67, 423, 7082]"},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"tokenized_data[\"train\"][\"attention_mask\"][0][:5]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-05T13:29:13.029589Z","iopub.execute_input":"2024-12-05T13:29:13.030036Z","iopub.status.idle":"2024-12-05T13:29:22.651343Z","shell.execute_reply.started":"2024-12-05T13:29:13.030007Z","shell.execute_reply":"2024-12-05T13:29:22.650527Z"}},"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"[1, 1, 1, 1, 1]"},"metadata":{}}],"execution_count":12},{"cell_type":"code","source":"# extracting train and eval sets from tokenized_data, which is a Dataset dictionaery\n# trimming the dataset to 1000 because of performance limitations\n\ntokenized_train_dataset = tokenized_data[\"train\"].shuffle(seed=42).select(range(1000))\ntokenized_eval_dataset = tokenized_data[\"test\"].shuffle(seed=42).select(range(1000))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-05T13:29:22.652414Z","iopub.execute_input":"2024-12-05T13:29:22.652768Z","iopub.status.idle":"2024-12-05T13:29:22.676897Z","shell.execute_reply.started":"2024-12-05T13:29:22.652724Z","shell.execute_reply":"2024-12-05T13:29:22.676281Z"}},"outputs":[],"execution_count":13},{"cell_type":"markdown","source":"## Initializing the model","metadata":{}},{"cell_type":"code","source":"# Number of labels in our classifier\nnum_labels = len(df[\"label\"].unique())\nnum_labels","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-05T13:29:22.677793Z","iopub.execute_input":"2024-12-05T13:29:22.678113Z","iopub.status.idle":"2024-12-05T13:29:22.686188Z","shell.execute_reply.started":"2024-12-05T13:29:22.678072Z","shell.execute_reply":"2024-12-05T13:29:22.685251Z"}},"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"3"},"metadata":{}}],"execution_count":14},{"cell_type":"code","source":"from transformers import GPT2ForSequenceClassification\n\n# Loading GPT-2 model for fine tuning\n# number of labels = number of emotions in our dataset\n\nmodel = GPT2ForSequenceClassification.from_pretrained(\"gpt2\", num_labels = num_labels)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-05T13:29:22.687226Z","iopub.execute_input":"2024-12-05T13:29:22.68787Z","iopub.status.idle":"2024-12-05T13:29:57.488384Z","shell.execute_reply.started":"2024-12-05T13:29:22.687831Z","shell.execute_reply":"2024-12-05T13:29:57.487494Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3e72cbfa27f74565aaa947c5b4c7ceb3"}},"metadata":{}},{"name":"stderr","text":"Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-05T13:29:57.489591Z","iopub.execute_input":"2024-12-05T13:29:57.490133Z","iopub.status.idle":"2024-12-05T13:29:57.496607Z","shell.execute_reply.started":"2024-12-05T13:29:57.490104Z","shell.execute_reply":"2024-12-05T13:29:57.49565Z"}},"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"GPT2ForSequenceClassification(\n  (transformer): GPT2Model(\n    (wte): Embedding(50257, 768)\n    (wpe): Embedding(1024, 768)\n    (drop): Dropout(p=0.1, inplace=False)\n    (h): ModuleList(\n      (0-11): 12 x GPT2Block(\n        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        (attn): GPT2SdpaAttention(\n          (c_attn): Conv1D(nf=2304, nx=768)\n          (c_proj): Conv1D(nf=768, nx=768)\n          (attn_dropout): Dropout(p=0.1, inplace=False)\n          (resid_dropout): Dropout(p=0.1, inplace=False)\n        )\n        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        (mlp): GPT2MLP(\n          (c_fc): Conv1D(nf=3072, nx=768)\n          (c_proj): Conv1D(nf=768, nx=3072)\n          (act): NewGELUActivation()\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n    )\n    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n  )\n  (score): Linear(in_features=768, out_features=3, bias=False)\n)"},"metadata":{}}],"execution_count":16},{"cell_type":"markdown","source":"## Creating Evaluation method to pass on to trainer","metadata":{}},{"cell_type":"code","source":"import evaluate\nimport numpy as np\n\nmetric = evaluate.load(\"accuracy\")\n\ndef compute_metrics(eval_pred):\n   logits, labels = eval_pred\n   predictions = np.argmax(logits, axis=-1)\n   return metric.compute(predictions=predictions, references=labels)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-05T13:29:57.497625Z","iopub.execute_input":"2024-12-05T13:29:57.497973Z","iopub.status.idle":"2024-12-05T13:29:58.751103Z","shell.execute_reply.started":"2024-12-05T13:29:57.497947Z","shell.execute_reply":"2024-12-05T13:29:58.750475Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/4.20k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"783046dc1aba414397863a5e6be4b49a"}},"metadata":{}}],"execution_count":17},{"cell_type":"markdown","source":"## Fine tuning","metadata":{}},{"cell_type":"code","source":"from transformers import TrainingArguments, Trainer","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-05T13:29:58.752116Z","iopub.execute_input":"2024-12-05T13:29:58.75261Z","iopub.status.idle":"2024-12-05T13:29:59.711089Z","shell.execute_reply.started":"2024-12-05T13:29:58.752582Z","shell.execute_reply":"2024-12-05T13:29:59.710178Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"# Configuring the trainer\ntraining_args = TrainingArguments(\n   output_dir=\"test_trainer\",\n   #evaluation_strategy=\"epoch\",\n   per_device_train_batch_size=1,  # Reduce batch size here\n   per_device_eval_batch_size=1,    # Optionally, reduce for evaluation as well\n   gradient_accumulation_steps=4,\n    report_to=\"none\"\n   )\n\n\ntrainer = Trainer(\n   model=model,\n   args=training_args,\n   train_dataset=tokenized_train_dataset,\n   eval_dataset=tokenized_eval_dataset,\n   compute_metrics=compute_metrics\n\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-05T13:30:45.418669Z","iopub.execute_input":"2024-12-05T13:30:45.419435Z","iopub.status.idle":"2024-12-05T13:30:45.459131Z","shell.execute_reply.started":"2024-12-05T13:30:45.419398Z","shell.execute_reply":"2024-12-05T13:30:45.458482Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"trainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-05T13:30:48.92256Z","iopub.execute_input":"2024-12-05T13:30:48.92335Z","iopub.status.idle":"2024-12-05T13:40:06.108675Z","shell.execute_reply.started":"2024-12-05T13:30:48.9233Z","shell.execute_reply":"2024-12-05T13:40:06.108018Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='375' max='375' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [375/375 09:15, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=375, training_loss=0.9870291341145834, metrics={'train_runtime': 556.4018, 'train_samples_per_second': 5.392, 'train_steps_per_second': 0.674, 'total_flos': 1567794659328000.0, 'train_loss': 0.9870291341145834, 'epoch': 3.0})"},"metadata":{}}],"execution_count":24},{"cell_type":"markdown","source":"## Model evaluation","metadata":{}},{"cell_type":"code","source":"import evaluate\ntrainer.evaluate()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-05T13:42:08.369228Z","iopub.execute_input":"2024-12-05T13:42:08.369653Z","iopub.status.idle":"2024-12-05T13:43:11.698446Z","shell.execute_reply.started":"2024-12-05T13:42:08.369621Z","shell.execute_reply":"2024-12-05T13:43:11.697687Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='500' max='500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [500/500 01:03]\n    </div>\n    "},"metadata":{}},{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"{'eval_loss': 0.7869201898574829,\n 'eval_accuracy': 0.697,\n 'eval_runtime': 63.3187,\n 'eval_samples_per_second': 15.793,\n 'eval_steps_per_second': 7.897,\n 'epoch': 3.0}"},"metadata":{}}],"execution_count":25},{"cell_type":"code","source":"# inferencing from the fine-tuned model\nfrom transformers import AutoModelForSequenceClassification, AutoTokenizer\nimport torch\n\n# specify model storage\nmodel_path = \"/kaggle/working/test_trainer/checkpoint-375\"\n\n# load the model and tokenizer\nmodel = AutoModelForSequenceClassification.from_pretrained(model_path)\ntokenizer = AutoTokenizer.from_pretrained(\"gpt2\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-05T13:45:10.383398Z","iopub.execute_input":"2024-12-05T13:45:10.384314Z","iopub.status.idle":"2024-12-05T13:45:10.835864Z","shell.execute_reply.started":"2024-12-05T13:45:10.384271Z","shell.execute_reply":"2024-12-05T13:45:10.834883Z"}},"outputs":[],"execution_count":26},{"cell_type":"code","source":"def predict(tweet):\n    # printing the tweet\n    print(\"Tweet: \", tweet)\n\n    # tokinze the input\n    inputs = tokenizer(tweet, return_tensors=\"pt\", truncation=True)\n\n    # get predictions\n    with torch.no_grad():\n        outputs = model(**inputs)\n\n    # get the logits\n    logits = outputs.logits\n\n    # convert logits to probabilities\n    probabilities = torch.softmax(logits, dim=-1)\n\n    # get predicted class\n    predicted_class = torch.argmax(probabilities, dim=-1).item()\n    print(\"Predicted class: \", predicted_class)\n\n    # Define the label mapping\n    label_mapping = {0: \"Negative\",\n                    1: \"Neutral\",\n                    2: \"Positive\"}\n\n    # get human readable label\n    sentiment = label_mapping[predicted_class]\n\n    print(f\"Sentiment: {sentiment}\", end=\"\\n\\n\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-05T13:51:38.639705Z","iopub.execute_input":"2024-12-05T13:51:38.640043Z","iopub.status.idle":"2024-12-05T13:51:38.646312Z","shell.execute_reply.started":"2024-12-05T13:51:38.640013Z","shell.execute_reply":"2024-12-05T13:51:38.645282Z"}},"outputs":[],"execution_count":31},{"cell_type":"code","source":"# preparing data for evaluation\nall_tweets = tokenized_eval_dataset[\"text\"]\n\nimport random\ntweets = random.sample(all_tweets, 5)\n[predict(tweet) for tweet in tweets]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-05T13:51:41.332097Z","iopub.execute_input":"2024-12-05T13:51:41.33305Z","iopub.status.idle":"2024-12-05T13:51:41.739184Z","shell.execute_reply.started":"2024-12-05T13:51:41.333002Z","shell.execute_reply":"2024-12-05T13:51:41.738219Z"}},"outputs":[{"name":"stdout","text":"Tweet:  Why is looking for girls names easier than looking for boys\nPredicted class:  1\nSentiment: Neutral\n\nTweet:  I`m a senior. I should of been already.\nPredicted class:  1\nSentiment: Neutral\n\nTweet:   ooh, work im afarid  looking forward to a sunny weekeknd tho!!!\nPredicted class:  2\nSentiment: Positive\n\nTweet:   yep  but I`m going better now\nPredicted class:  0\nSentiment: Negative\n\nTweet:  The Heater blew up\nPredicted class:  0\nSentiment: Negative\n\n","output_type":"stream"},{"execution_count":32,"output_type":"execute_result","data":{"text/plain":"[None, None, None, None, None]"},"metadata":{}}],"execution_count":32},{"cell_type":"code","source":"predict(\"ohh man\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-05T13:52:45.318762Z","iopub.execute_input":"2024-12-05T13:52:45.319656Z","iopub.status.idle":"2024-12-05T13:52:45.375204Z","shell.execute_reply.started":"2024-12-05T13:52:45.319623Z","shell.execute_reply":"2024-12-05T13:52:45.37436Z"}},"outputs":[{"name":"stdout","text":"Tweet:  ohh man\nPredicted class:  1\nSentiment: Neutral\n\n","output_type":"stream"}],"execution_count":39}]}